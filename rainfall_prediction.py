# -*- coding: utf-8 -*-
"""rainfall_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YRfCWIVqgxsmQvz2EMlV4o-cZbxhahh2
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from sklearn.preprocessing import StandardScaler

# Read the CSV file into a DataFrame
df = pd.read_csv('indiarainfall.csv')

# Plot the rainfall data
df.plot(x='YEAR', y=['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC'], figsize=(14, 8))

# Customize the plot
plt.title('Monthly Rainfall in India')
plt.ylabel('Rainfall (mm)')
plt.xlabel('Year')
plt.legend(title='Month')
plt.show()

annual_rainfall = df['ANNUAL']
print(annual_rainfall)
cols=list(df)[14:15]

training_df=df[cols].astype(float)
plot_df=training_df
plot_df.plot.line()

from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler to the annual rainfall data
scaler.fit(df[['ANNUAL']])

# Transform the annual rainfall data using the fitted scaler
annual_rainfall_scaled = scaler.transform(df[['ANNUAL']])

# Print the scaled data
print(annual_rainfall_scaled)

'''from sklearn.model_selection import train_test_split

# Split the data into training and test sets
trainX, testX, trainY, testY = train_test_split(trainX, trainY, test_size=0.2)

# Print the shapes of the training and test sets
print('Shape of training data (X):', trainX.shape)
print(trainX)
print('Shape of training data (Y):', trainY.shape)
print('Shape of test data (X):', testX.shape)
print('Shape of test data (Y):', testY.shape)

'''
from sklearn.model_selection import train_test_split

# Lists for storing the training and testing data
trainX = []
trainY = []

n_past = 20  # 20 values will be considered to predict the next value

# Adding the values to trainX and trainY lists
for i in range(n_past, len(annual_rainfall_scaled)):
    trainX.append(annual_rainfall_scaled[i - n_past:i])
    trainY.append(annual_rainfall_scaled[i])

# Converting into numpy arrays
trainX, trainY = np.array(trainX), np.array(trainY)

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.2, shuffle=False)

print('X_train shape == {}'.format(X_train.shape))
print('y_train shape == {}'.format(y_train.shape))
print('X_test shape == {}'.format(X_test.shape))
print('y_test shape == {}'.format(y_test.shape))

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout

# Define the model
model = Sequential()

# Add the first LSTM layer
model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))
model.add(Dropout(0.2))

# Add the second LSTM layer
model.add(LSTM(32, activation='relu', return_sequences=True))
model.add(Dropout(0.2))

# Add the third LSTM layer
model.add(LSTM(32, activation='relu', return_sequences=False))
model.add(Dropout(0.2))

from keras.regularizers import l2

# Add L2 regularization to Dense layers
model.add(Dense(trainY.shape[1], kernel_regularizer=l2(0.01)))

# Add the output layer
model.add(Dense(trainY.shape[1]))

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Print the model summary
model.summary()

history = model.fit(trainX, trainY, epochs=100, batch_size=20, validation_split=0.1, verbose=1)

import matplotlib.pyplot as plt

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

# Evaluate the model on the test data


mse = model.evaluate(X_test, y_test)

# Print the MSE
print("Test MSE:", mse)
# Evaluate the model on training and testing data
train_loss = model.evaluate(X_train, y_train, verbose=0)
test_loss = model.evaluate(X_test, y_test, verbose=0)

# Print the MSE values
print("Training MSE:", train_loss)
print("Testing MSE:", test_loss)
#This code will print the Mean Squared Error (MSE)

from sklearn.metrics import r2_score

# Predict on training and validation sets
train_pred = model.predict(X_train)
val_pred = model.predict(X_test)

# Calculate R-squared (R^2) score for training and validation sets
train_r2 = r2_score(y_train, train_pred)
val_r2 = r2_score(y_test, val_pred)

# Print the R-squared (R^2) scores
print("Training R-squared (R^2) score:", train_r2)
print("Validation R-squared (R^2) score:", val_r2)


from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Predict on training and validation sets
train_pred = model.predict(X_train)
val_pred = model.predict(X_test)

# Calculate evaluation metrics for training set
train_mae = mean_absolute_error(y_train, train_pred)
train_rmse = mean_squared_error(y_train, train_pred, squared=False)
train_r2 = r2_score(y_train, train_pred)

# Calculate evaluation metrics for validation set
val_mae = mean_absolute_error(y_test, val_pred)
val_rmse = mean_squared_error(y_test, val_pred, squared=False)
val_r2 = r2_score(y_test, val_pred)

# Create a DataFrame to store the evaluation metrics
metrics_df = pd.DataFrame({
    'Metric': ['MAE', 'RMSE', 'R-squared'],
    'Training': [train_mae, train_rmse, train_r2],
    'Validation': [val_mae, val_rmse, val_r2]
})

# Print the accuracy table
print(metrics_df)

from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay
from sklearn.preprocessing import StandardScaler
us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())

n_past = 100
n_days_for_prediction=100

#predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq=us_bd).tolist()
#years = [date.year for date in predict_period_dates]
start_year = 2024
end_year = 2034  # Predicting for the next 10 years

# Generate a list of dates for the extended prediction period
extended_predict_period_dates = pd.date_range(start=f"{start_year}-01-01", end=f"{end_year}-12-31", freq=us_bd).tolist()

#print(years)

# make prediction
#prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction
# Make predictions for the extended prediction period
#print(extended_predict_period_dates)
extended_prediction = model.predict(trainX[-len(extended_predict_period_dates):])
#print(len(extended_prediction))
#print(prediction)
#Perform inverse transformation to rescale back to original range
#Since we used 1 variables for transform, the inverse expects same dimensions

extended_prediction_copies = np.repeat(extended_prediction, training_df.shape[1], axis=-1)
y_pred_extended = scaler.inverse_transform(extended_prediction_copies)[:, 0]
#print(y_pred_extended)
df_extended_forecast = pd.DataFrame({'YEAR': [date.year for date in extended_predict_period_dates],
                                    # "Month" : [date.month for date in extended_predict_period_dates],
                                     'ANNUAL': y_pred_extended})

df_list = df_extended_forecast.values.tolist()
predictions = []
year = []

for i in range (start_year, end_year+1):
  count = 0
  data= []
  for j in range(len(df_list)):
    if int(df_list[j][0]) == i:
      data.append(df_list[j][1])
      count +=1
  actual_rain = sum(data)/len(data)
  #print(count)
  predictions.append(actual_rain)
  year.append(i)
#print(df_list)
#print(predictions)
#print(year)

import matplotlib.pyplot as plt


# Plotting the line graph
plt.plot(year, predictions, marker='o', color='blue', label='Prediction')

# Adding labels and title
plt.xlabel('Year')
plt.ylabel('Prediction')
plt.title('Prediction over Years')

# Show plot
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()